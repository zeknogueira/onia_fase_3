{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bbc12c6-006b-447f-b354-0aa20ca1b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7047ec4-8a34-422e-9f9a-b0bc921096a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivos\n",
    "\n",
    "#caminho para rodar google colab\n",
    "#arq_treinamento = pd.read_csv('treino.csv')\n",
    "#arq_teste = pd.read_csv('teste.csv')\n",
    "\n",
    "\n",
    "#caminhos para rodar localmente\n",
    "arq_treinamento = pd.read_csv('arquivos/brutos/treino.csv')\n",
    "arq_teste = pd.read_csv('arquivos/brutos/teste.csv')\n",
    "\n",
    "\n",
    "def arq_treinamento_info():\n",
    "    \n",
    "    print(arq_treinamento.head())\n",
    "    print(arq_treinamento.info())\n",
    "    print(arq_treinamento.describe())\n",
    "    print(arq_treinamento.isnull().sum())\n",
    "\n",
    "\n",
    "#definindo target e características arquivo de treinamento\n",
    "arq_treinamento_x = arq_treinamento.drop(columns=['target', 'id'])\n",
    "\n",
    "arq_treinamento_y = arq_treinamento['target']\n",
    "\n",
    "\n",
    "\n",
    "#train_test_split dos dados de teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arq_treinamento_x, arq_treinamento_y, test_size=0.2, random_state=42)\n",
    "\n",
    "#targets estao desbalanceados\n",
    "#arq_treinamento_y.value_counts()\n",
    "y_train.value_counts()\n",
    "\n",
    "def split_info():\n",
    "    print(\"Dados de treinamento (X_train):\")\n",
    "    print(X_train)\n",
    "    print(\"Labels de treinamento (y_train):\")\n",
    "    print(y_train)\n",
    "    print(\"Dados de teste (X_test):\")\n",
    "    print(X_test)\n",
    "    print(\"Labels de teste (y_test):\")\n",
    "    print(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df82d512-7940-4bed-96a4-6382e0190bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  F1 Balanceada\n",
      "0   Random Forest       0.757623\n",
      "1         XGBoost       0.748710\n",
      "2  Neural Network       0.704308\n"
     ]
    }
   ],
   "source": [
    "#treinamento do RandomForest, XGB e NeuralNerwork com dados balanceados com SMOTETomek ADASYN\n",
    "#usando Pipeline #validacao_cruzada #f1_score\n",
    "\n",
    "random_state_42 = 42\n",
    "\n",
    "balanceador = Pipeline([\n",
    "    ('adasyn', ADASYN(random_state=random_state_42)),\n",
    "    ('smote_tomek_balanceamento', SMOTETomek(random_state=random_state_42))\n",
    "])\n",
    "\n",
    "\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "#validacao cruzada com stratifieldkfold\n",
    "validacao_cruzada = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    f1_macro_scores = []\n",
    "    f1_micro_scores = []\n",
    "    f1_balanceada_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for treino_dados, validacao_dados in validacao_cruzada.split(X_train, y_train):\n",
    "        X_train_vc, X_val_vc = X_train.iloc[treino_dados], X_train.iloc[validacao_dados]\n",
    "        y_train_vc, y_val_vc = y_train.iloc[treino_dados], y_train.iloc[validacao_dados]\n",
    "\n",
    "\n",
    "        X_rebalanceado, y_rebalanceado = balanceador.fit_resample(X_train_vc, y_train_vc)\n",
    "\n",
    "        modelo.fit(X_rebalanceado, y_rebalanceado)\n",
    "\n",
    "        y_pred = modelo.predict(X_val_vc)\n",
    "\n",
    "        ac_score = accuracy_score(y_val_vc, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "        f1_balanceada = f1_score(y_val_vc, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_val_vc, y_pred, average='macro')\n",
    "        f1_micro = f1_score(y_val_vc, y_pred, average='micro')\n",
    "\n",
    "        accuracy_scores.append(ac_score)\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "        f1_micro_scores.append(f1_micro)\n",
    "        f1_balanceada_scores.append(f1_balanceada)\n",
    "\n",
    "\n",
    "        \"\"\"matriz_confusao = confusion_matrix(y_val_vc, y_pred)\n",
    "        display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "        display.plot(cmap='Blues')\n",
    "        plt.title(f'{name} - Fold')\n",
    "        print(name, matriz_confusao)\n",
    "        plt.show()\"\"\"\n",
    "\n",
    "    #resultados: média das métricas dos folds\n",
    "\n",
    "    \"\"\"resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": np.mean(accuracy_scores),\n",
    "        \"F1 Macro\": np.mean(f1_macro_scores),\n",
    "        \"F1 Micro\": np.mean(f1_micro_scores),\n",
    "        \"F1 Balanceada\": np.mean(f1_balanceada_scores)\n",
    "    })\"\"\"\n",
    "\n",
    "    # priorizando a métrica f1-score que será cobrada\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "      # \"Accuracy\": np.mean(accuracy_scores),\n",
    "       # \"F1 Macro\": np.mean(f1_macro_scores),\n",
    "       # \"F1 Micro\": np.mean(f1_micro_scores),\n",
    "        \"F1 Balanceada\": np.mean(f1_balanceada_scores)\n",
    "    })\n",
    "\n",
    "\n",
    "print(pd.DataFrame(resultados))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007ed2c4-4ea2-48f5-871f-690c3107394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network não deu resultado\n",
    "#GridSearchCV não foi possível por conta do Hardware. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487ca4fd-9aa9-4a52-9bcf-f558289c1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testando RandomSearchCV com RandomForest\n",
    "#fazendo balanceamento dos dados fora da validacao cruzada para fazer o randomsearchCV\n",
    "\n",
    "random_state_42 = 42\n",
    "\n",
    "balanceador = Pipeline([\n",
    "    ('adasyn', ADASYN(random_state=random_state_42)),\n",
    "    ('smote_tomek_balanceamento', SMOTETomek(random_state=random_state_42))\n",
    "])\n",
    "\n",
    "X_rebalanceado_smote_tomek_adasyn, y_rebalanceado_smote_tomek_adasyn = balanceador.fit_resample(\n",
    "    X_train, y_train)\n",
    "\n",
    "#print(X_rebalanceado_smote_tomek_adasyn)\n",
    "#print(y_rebalanceado_smote_tomek_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87478402-9649-4500-9b3e-87f4b410cdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "melhores parametros: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "#Testando RandomSearchCV com RandomForest\n",
    "\n",
    "parametros_dicionario = {\n",
    "    'n_estimators': [100, 300, 500, 800], \n",
    "    'max_depth': [None, 10, 20, 30], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "random_modelo = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "random_search_config = RandomizedSearchCV(\n",
    "    random_modelo, parametros_dicionario, \n",
    "    n_iter=10,  #menos testes para conseguir rodar\n",
    "    scoring='f1_weighted', \n",
    "    cv=3,  # Validação cruzada com 3 folds (mais rápido)\n",
    "    verbose=2, \n",
    "    n_jobs=-1,  # Usa todos os núcleos do processador\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_config.fit(X_rebalanceado_smote_tomek_adasyn, y_rebalanceado_smote_tomek_adasyn)\n",
    "\n",
    "print(\"melhores parametros:\", random_search_config.best_params_)\n",
    "\n",
    "#resultados:\n",
    "#melhores parametros: {'n_estimators': 300, 'min_samples_split': 2, \n",
    "#'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4dc82-83a2-45a5-8bbb-a71dd0836504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "#Testando RandomSearchCV com XGB\n",
    "\n",
    "parametros_dicionario = {\n",
    "    'n_estimators': [100, 300, 500, 800], \n",
    "    'max_depth': [3, 5, 10, 20], \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2], \n",
    "    'subsample': [0.6, 0.8, 1.0], \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_modelo = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    xgb_modelo, parametros_dicionario, \n",
    "    n_iter=10,  # menos testes\n",
    "    scoring='f1_weighted', \n",
    "    cv=3,  # Validação cruzada com 3 folds (mais rápido)\n",
    "    verbose=2, \n",
    "    n_jobs=-1,  # Usa todos os núcleos do processador\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_rebalanceado_smote_tomek_adasyn, y_rebalanceado_smote_tomek_adasyn)\n",
    "\n",
    "# Exibir melhores parâmetros\n",
    "print(\"Melhores parâmetros\", random_search_xgb.best_params_)\n",
    "\n",
    "#resultados:\n",
    "#Melhores parâmetros {'subsample': 1.0, 'n_estimators': 500, \n",
    "#'max_depth': 20, 'learning_rate': 0.2, 'colsample_bytree': 0.8}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa9e2c-ed02-4509-9793-9d9a64ba4bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
