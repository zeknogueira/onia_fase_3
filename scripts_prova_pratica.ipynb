{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d89d99-9e10-4bba-85b5-da463ce146d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#xgboost não está incorporado ao Scikit Learn: verificar se não terá problemas com as regras.\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c78badc0-4ed3-4cef-9c40-2a3a6b2a675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq_treinamento = pd.read_csv('arquivos/brutos/treino.csv')\n",
    "arq_teste = pd.read_csv('arquivos/brutos/teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019c067e-8527-41e5-9369-6f9adcc63b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      col_0     col_1     col_2      col_3      col_4     col_5  \\\n",
      "0  12251  38.763463  4.372530  2.888516  12.352539  18.906550  9.605924   \n",
      "1   4529  32.192181  3.158109  2.134617  16.193530  26.786878  9.347958   \n",
      "2  11284  28.370782  3.006067  1.969280  15.163950  28.515109  7.946870   \n",
      "3  10993  38.215409  2.174232  2.935104  11.501867  18.419571  7.954005   \n",
      "4  12927  38.904545  2.956164  2.253149  12.282552  25.547887  8.168776   \n",
      "\n",
      "      col_6     col_7     col_8     col_9     col_10     col_11    col_12  \\\n",
      "0  3.456596  3.959477  4.738227  3.692509  11.192263   9.076242  4.692962   \n",
      "1  5.093277  6.893790  3.399840  2.080853  19.486692  12.349952  3.217670   \n",
      "2  5.609813  6.511194  3.256799  2.290993  18.405205  14.781329  3.231217   \n",
      "3  4.229832  4.522060  4.869234  3.383514  12.782517  17.343742  5.009182   \n",
      "4  3.653026  6.809110  4.971130  2.127363  19.247327  20.115183  3.560524   \n",
      "\n",
      "   target  \n",
      "0       2  \n",
      "1       0  \n",
      "2       0  \n",
      "3       2  \n",
      "4       3  \n"
     ]
    }
   ],
   "source": [
    "print(arq_treinamento.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee525bee-ecc5-4c86-b06e-bf0940037c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#informacoes arquivo de treinamento \n",
    "\n",
    "#print(arq_treinamento.info())\n",
    "\n",
    "#print(arq_treinamento.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7793a438-8e7d-4d3f-83bc-dbcafbaddd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informacoes arquivo de treinamento print (arq_treinamento.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0757332f-b33f-48a7-9ea1-cac22812d3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027ff9c-2815-49e9-9936-cacc512cc3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc2672e-1910-4bae-8634-8dfc97bf1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo target e características\n",
    "arq_treinamento_x = arq_treinamento.drop(columns=['target', 'id'])\n",
    "\n",
    "arq_treinamento_y = arq_treinamento['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19894bd3-aa9a-4329-9194-7e0dc1771864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    5096\n",
       "4    1609\n",
       "1    1593\n",
       "2    1389\n",
       "3     813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando se as classes estão balanceadas\n",
    "\n",
    "arq_treinamento_y.value_counts()\n",
    "\n",
    "#classes estão desbalanceadas. Não vou utilizar Acuraccy Score para Medir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d621c9aa-8c1b-40ce-879c-b1f63b121db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo o train_split_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(arq_treinamento_x, arq_treinamento_y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9295b58-8c47-4ee0-83c2-c5ddca2c3bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    1023\n",
       "1     334\n",
       "4     306\n",
       "2     281\n",
       "3     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa936e4-1413-4c5a-bcb9-c1ba93df562e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3143195698.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"\"\"\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#verificando as divisoes:\n",
    "\"\"\"\n",
    "print(\"Dados de treinamento (X_train):\")\n",
    "print(X_train)\n",
    "print(\"Labels de treinamento (y_train):\")\n",
    "print(y_train)\n",
    "\n",
    "print(\"Dados de teste (X_test):\")\n",
    "print(X_test)\n",
    "print(\"Labels de teste (y_test):\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20cd5a-ce56-4a15-9a34-85f8c6c7e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest: definindo o modelo\n",
    "\"\"\"\n",
    "modelo_random_forest = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcf8a0-ff2a-428b-8e57-5fb06f9cab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest: treinando o modelo\n",
    "\"\"\"modelo_random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108da9ba-a814-40e3-af61-55c1e396da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest: fazendo as predições\n",
    "\"\"\"\n",
    "randomforest_pred = modelo_random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b23452-4420-4a6d-bce7-c917b08c6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(len(randomforest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0246a-526b-4c68-9237-12fc72c8780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest: matriz de confusão\n",
    "\"\"\"matriz_confusao = confusion_matrix(y_test, randomforest_pred)\n",
    "print(matriz_confusao)\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "display.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba1149-eb45-41bd-99b8-f9f2df72e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f75b5-cb7b-46e3-971d-ed7833a98360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest: verificando o relatório de classificação\n",
    "\"\"\"\n",
    "print(classification_report(y_test, randomforest_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f64433-5cf9-4e63-ae58-4e69ba940fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN: definindo o modelo\n",
    "\"\"\"\n",
    "modelo_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "modelo_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee2e76-fbc9-47fe-bda7-2cb4242b6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN: treinando o modelo\n",
    "\"\"\"\n",
    "knn_pred = modelo_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac24985-645d-4eda-8441-f1d90ae9e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN: matriz de confusão\n",
    "\"\"\"matriz_confusao = confusion_matrix(y_test, knn_pred)\n",
    "print(matriz_confusao)\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "display.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39596c-50eb-44e8-8df0-1ce1f50c3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN: verificando o relatório de classificação\n",
    "\"\"\"\n",
    "\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605ac1f-eab2-42cc-a0a5-97c1729420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando diversos modelos de uma vez\n",
    "\"\"\"random_state_42 = 42\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"KNN\": KNeighborsClassifier(), #nao precisa do random_state\n",
    "    \"SVM\": SVC(random_state=random_state_42), #nao defini o kernel, irá usar automaticamente o RBF\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=random_state_42),\n",
    "    \"Naive Bayes\": MultinomialNB(), #nao precisa do random_state\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ac_score = accuracy_score(y_test, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "    \n",
    "    f1_balanceada = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": ac_score,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Micro\": f1_micro,\n",
    "        \"F1 Balanceada\": f1_balanceada\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44ae88-de25-47a7-9628-ac40200ba602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando resultados para dados balanceados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d81913-babb-48f4-bcdc-f2f97c21abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling (aumenta as classes com menos amostras, criando artificialmente amostras das classes menores)\n",
    "\"\"\"\n",
    "smote_balanceamento = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_rebalanceado, y_train_rebalanceado = smote_balanceamento.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_rebalanceado.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba05405-6fe3-44de-8c34-b28bae0aafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling: testando diversos modelos de uma vez\n",
    "\"\"\"random_state_42 = 42\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"KNN\": KNeighborsClassifier(), #nao precisa do random_state\n",
    "    \"SVM\": SVC(random_state=random_state_42), #nao defini o kernel, irá usar automaticamente o RBF\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=random_state_42),\n",
    "    \"Naive Bayes\": MultinomialNB(), #nao precisa do random_state\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    modelo.fit(X_train_rebalanceado, y_train_rebalanceado)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ac_score = accuracy_score(y_test, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "    \n",
    "    f1_balanceada = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": ac_score,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Micro\": f1_micro,\n",
    "        \"F1 Balanceada\": f1_balanceada\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4239c-b33a-4178-a248-fef615da9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling (diminui o número de amostras das classes maiores para igualar com as menores)\n",
    "\"\"\"\n",
    "\n",
    "undersampler_balanceamento = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_under_rebalanceado, y_train_under_rebalanceado = undersampler_balanceamento.fit_resample(X_train, y_test)\n",
    "\n",
    "y_train_under_rebalanceado.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a5ffa-31b5-4e6b-a9c0-fc2c49543978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling: testando diversos modelos de uma vez\n",
    "\"\"\"random_state_42 = 42\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"KNN\": KNeighborsClassifier(), #nao precisa do random_state\n",
    "    \"SVM\": SVC(random_state=random_state_42), #nao defini o kernel, irá usar automaticamente o RBF\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=random_state_42),\n",
    "    \"Naive Bayes\": MultinomialNB(), #nao precisa do random_state\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    modelo.fit(X_train_under_rebalanceado, y_train_under_rebalanceado)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ac_score = accuracy_score(y_test, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "    \n",
    "    f1_balanceada = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": ac_score,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Micro\": f1_micro,\n",
    "        \"F1 Balanceada\": f1_balanceada\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05530ab3-65d2-4638-aa42-58acae8c84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under não rolou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c3325-898a-4537-85c0-070d29faf844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930f000-f710-4637-9693-1d77099ecd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melhores resultados:\n",
    "#Random Forest, XGBoost e NeuralNetWork\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e7ade-6ca3-40f6-b20f-8a8c68dcd7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Oversampling: verificanco matriz de confusão dos três melhores modelos\n",
    "\n",
    "random_state_42 = 42\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    modelo.fit(X_train_rebalanceado, y_train_rebalanceado)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ac_score = accuracy_score(y_test, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "    \n",
    "    f1_balanceada = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "    display.plot(cmap='Blues')\n",
    "    plt.title(name)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.show()\n",
    "\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": ac_score,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Micro\": f1_micro,\n",
    "        \"F1 Balanceada\": f1_balanceada\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2559fa1-a65c-4536-a7f8-c4770b5fb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Oversampling SMOTE+Tomek Links: ( Combina o SMOTE com uma técnica de retirada de ruídos)\n",
    "#verificanco matriz de confusão dos três melhores modelos\n",
    "\n",
    "random_state_42 = 42\n",
    "smote_tomek_balanceamento = SMOTETomek(random_state=random_state_42)\n",
    "X_train_rebalanceado_smotetomek, y_train_rebalanceado_smotetomek = smote_tomek_balanceamento.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_rebalanceado_smotetomek.value_counts()\n",
    "\n",
    "\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    modelo.fit(X_train_rebalanceado_smotetomek, y_train_rebalanceado_smotetomek)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ac_score = accuracy_score(y_test, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "    \n",
    "    f1_balanceada = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "    matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "    display.plot(cmap='Blues')\n",
    "    plt.title(name)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    print(name, matriz_confusao)\n",
    "    plt.show()\n",
    "\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": ac_score,\n",
    "        \"F1 Macro\": f1_macro,\n",
    "        \"F1 Micro\": f1_micro,\n",
    "        \"F1 Balanceada\": f1_balanceada\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bdd30-4657-4768-85d1-0167f9520b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Oversampling SMOTE+Tomek Links: ( Combina o SMOTE com uma técnica de retirada de ruídos)\n",
    "#verificanco a F1-score com validação cruzada\n",
    "#matriz de confusão dos três melhores modelos\n",
    "\n",
    "random_state_42 = 42\n",
    "smote_tomek_balanceamento = SMOTETomek(random_state=random_state_42)\n",
    "\n",
    "\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "#validacao cruzada com stratifieldkfold\n",
    "validacao_cruzada = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    f1_macro_scores = []\n",
    "    f1_micro_scores = []\n",
    "    f1_balanceada_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for treino_dados, validacao_dados in validacao_cruzada.split(X_train, y_train):\n",
    "        X_train_vc, X_val_vc = X_train.iloc[treino_dados], X_train.iloc[validacao_dados]\n",
    "        y_train_vc, y_val_vc = y_train.iloc[treino_dados], y_train.iloc[validacao_dados]\n",
    "\n",
    "        X_rebalanceado, y_rebalanceado = smote_tomek_balanceamento.fit_resample(X_train_vc, y_train_vc)\n",
    "\n",
    "        modelo.fit(X_rebalanceado, y_rebalanceado)\n",
    "\n",
    "        y_pred = modelo.predict(X_val_vc)\n",
    "\n",
    "        ac_score = accuracy_score(y_val_vc, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "        f1_balanceada = f1_score(y_val_vc, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_val_vc, y_pred, average='macro')\n",
    "        f1_micro = f1_score(y_val_vc, y_pred, average='micro')\n",
    "\n",
    "        accuracy_scores.append(ac_score)\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "        f1_micro_scores.append(f1_micro)\n",
    "        f1_balanceada_scores.append(f1_balanceada)\n",
    "\n",
    "        \n",
    "        matriz_confusao = confusion_matrix(y_val_vc, y_pred)\n",
    "        display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "        display.plot(cmap='Blues')\n",
    "        plt.title(f'{name} - Fold')\n",
    "        print(name, matriz_confusao)\n",
    "        plt.show()\n",
    "\n",
    "    #resultados: média das métricas dos folds\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": np.mean(accuracy_scores),\n",
    "        \"F1 Macro\": np.mean(f1_macro_scores),\n",
    "        \"F1 Micro\": np.mean(f1_micro_scores),\n",
    "        \"F1 Balanceada\": np.mean(f1_balanceada_scores)\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d68c9-3256-42e7-b417-0775c2ed7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados com validação cruzada são mais confiáveis por oferecerem generalização. \n",
    "#RandomForest se mostrou melhor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40e485-2a6d-4d98-928b-c2750efcd46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Aprimorando o balanceamento dos dados\n",
    "#ADASYN\n",
    "#usando Pipeline\n",
    "\n",
    "random_state_42 = 42\n",
    "\n",
    "balanceador = Pipeline([\n",
    "    ('adasyn', ADASYN(random_state=random_state_42)),\n",
    "    ('smote_tomek_balanceamento', SMOTETomek(random_state=random_state_42))\n",
    "])\n",
    "\n",
    "\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=random_state_42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective=\"multi:softmax\", num_class=5, random_state=random_state_42),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "#validacao cruzada com stratifieldkfold\n",
    "validacao_cruzada = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_42)\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, modelo in modelos.items():\n",
    "    f1_macro_scores = []\n",
    "    f1_micro_scores = []\n",
    "    f1_balanceada_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for treino_dados, validacao_dados in validacao_cruzada.split(X_train, y_train):\n",
    "        X_train_vc, X_val_vc = X_train.iloc[treino_dados], X_train.iloc[validacao_dados]\n",
    "        y_train_vc, y_val_vc = y_train.iloc[treino_dados], y_train.iloc[validacao_dados]\n",
    "\n",
    "\n",
    "        #adicionando o ADASYN\n",
    "        X_rebalanceado, y_rebalanceado = balanceador.fit_resample(X_train_vc, y_train_vc)\n",
    "\n",
    "        modelo.fit(X_rebalanceado, y_rebalanceado)\n",
    "\n",
    "        y_pred = modelo.predict(X_val_vc)\n",
    "\n",
    "        ac_score = accuracy_score(y_val_vc, y_pred) #nao será muito útil por que os dados são multiclasse, mas pode ser interessante verificar diferenças gritantes\n",
    "        f1_balanceada = f1_score(y_val_vc, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_val_vc, y_pred, average='macro')\n",
    "        f1_micro = f1_score(y_val_vc, y_pred, average='micro')\n",
    "\n",
    "        accuracy_scores.append(ac_score)\n",
    "        f1_macro_scores.append(f1_macro)\n",
    "        f1_micro_scores.append(f1_micro)\n",
    "        f1_balanceada_scores.append(f1_balanceada)\n",
    "\n",
    "        \n",
    "        matriz_confusao = confusion_matrix(y_val_vc, y_pred)\n",
    "        display = ConfusionMatrixDisplay(confusion_matrix=matriz_confusao)\n",
    "        display.plot(cmap='Blues')\n",
    "        plt.title(f'{name} - Fold')\n",
    "        print(name, matriz_confusao)\n",
    "        plt.show()\n",
    "    \n",
    "    #resultados: média das métricas dos folds\n",
    "    \n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": np.mean(accuracy_scores),\n",
    "        \"F1 Macro\": np.mean(f1_macro_scores),\n",
    "        \"F1 Micro\": np.mean(f1_micro_scores),\n",
    "        \"F1 Balanceada\": np.mean(f1_balanceada_scores)\n",
    "    })\n",
    "    \n",
    "    # priorizando a métrica f1-score que será cobrada\n",
    "    resultados.append({\n",
    "        \"Model\": name,\n",
    "      # \"Accuracy\": np.mean(accuracy_scores),\n",
    "       # \"F1 Macro\": np.mean(f1_macro_scores),\n",
    "       # \"F1 Micro\": np.mean(f1_micro_scores),\n",
    "        \"F1 Balanceada\": np.mean(f1_balanceada_scores)\n",
    "    })\n",
    "    \n",
    "\n",
    "print(pd.DataFrame(resultados))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed89af5-db73-43e4-aab2-1a5222a2523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN não teve muito efeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264e3da-7880-4432-8a4e-25817f94ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rede Neural também não está performando. Vou seguir somente com RF e XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e5cdd-90ce-4d35-a159-bec5abc9fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando os melhores hiperparâmetros com GridSearch: RandomForestClassifier\n",
    "\"\"\"\n",
    "print(\"tamanho do conjunto X_train\", len(X_train))\n",
    "print(\"classes antes do balanceamento:\")\n",
    "y_train.value_counts()\n",
    "\"\"\"\n",
    "random_state_42 = 42\n",
    "\n",
    "balanceador = Pipeline([\n",
    "    ('adasyn', ADASYN(random_state=random_state_42)),\n",
    "    ('smote_tomek_balanceamento', SMOTETomek(random_state=random_state_42))\n",
    "])\n",
    "\n",
    "X_rebalanceado_smote_tomek_adasyn, y_rebalanceado_smote_tomek_adasyn = balanceador.fit_resample(X_train, y_train)\n",
    "\"\"\"\n",
    "print(\"tamanho do conjunto X_train rebalanceado SMOTETomek ADASYN\", len(X_rebalanceado_smote_tomek_adasyn))\n",
    "print(\"classes depois do balanceamento SMOTETomek ADASYN:\")\n",
    "y_rebalanceado_smote_tomek_adasyn.value_counts()\n",
    "\"\"\"\n",
    "dicionario_parametros = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "referencias = GridSearchCV(RandomForestClassifier(random_state=random_state_42), dicionario_parametros,\n",
    "                           scoring='f1_weighted', cv=5, n_jobs=2)\n",
    "referencias.fit(X_rebalanceado_smote_tomek_adasyn, y_rebalanceado_smote_tomek_adasyn)\n",
    "\n",
    "print(\"Melhores parâmetros SMOTETomek ADASYN\\n\", referencias.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb751b73-554e-4e47-b01b-ccd51dfcfc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
